---
title: "Lab 1 Group B 12"
author: "Axel Holmberg (axeho681), Jonathan Reimertz (jonre639) and Wilhelm Hansson"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=5, fig.height=3, fig.align = "center")
library(kknn)
```

# Assignment 1
## 1.
*Import the data into R and divide it into training and test sets (50%/50%)*
```{r Task1, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
data <- read.csv2("spambase.csv")

#Split data into training and test set.

n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
```

## 2.
*Use logistic regression (functions glm(), predict()) to classify the training and test data by the classification principle $\hat{Y}=1$ if $(Y=1|X) > 0.5$, otherwise $\hat{Y}=0$ and report the confusion matrices (use table()) and the misclassification rates for training and test data. Analyse the obtained results.*

```{r Task 2, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
#GLM model for data with family
#binomial --> only 0s and 1s
model <- glm(Spam ~ ., family=binomial, data=train) 

predictModel= predict(model, newdata=test, type="response") 

#Split up the model into spam and 
#not spam
probability <- ifelse(predictModel > 0.5, "1", "0") 

confMatrix <- table(probability, test[,"Spam"]) #Confusionmatrix from the model
#Diagonal of the misclassfication rate by dividing the 
#diagonal from the confusionmatricx with the whole confusionmatrix
modelDiag <- diag(confMatrix) 
missClMa1 = 1-(sum(modelDiag)/sum(confMatrix)) 

#Prints results
print("Confusion matrix 2:")
print(confMatrix)
print("missclassification 2:")
print(missClMa1)
```

##### Analyse the obtained results.
The confusion matrix gives us the misclassification rate. I would say that the misclassification rate is okay for its' aplication. It is all very dependent on the use case though.

## 3.
*Use logistic regression to classify the test data by the classification principle $\hat{Y}=1$ if $p(Y=1|X) > 0.8$, otherwise $\hat{Y}=0$ and report the confusion matrices (use table()) and the misclassification rates for training and test data. Compare the results. What effect did the new rule have?*

```{r}
#Split up the model into spam and not spam
probability2 <- ifelse(predictModel > 0.8, "1", "0") 

confMatrix2 <- table(probability2, test[,"Spam"]) 

modelDiag2 <- diag(confMatrix2)

missClMa2 = 1-(sum(modelDiag2)/sum(confMatrix2))


print("Confusion matrix 3:")
print(confMatrix2)
print("missclassification 3:")
print(missClMa2)
```

##### What effects did the new rule have?
The new rule made it so that the rate is a bit worse, so it should stay at the previous value.


## 4.
*Use standard classifier kknn() with K=30 from package kknn, report the the misclassification rates for the training and test data and compare the results with step 2.*
```{r}
#KKNN with K=30

kknn_K30 = kknn(Spam ~ ., train=train, test=test, k=30)
kknn_K30_pred = predict(kknn_K30)

#Split up the model into spam and not spam
kknn_K30_pred <- ifelse(kknn_K30_pred > 0.5, 1, 0) 


confMa_K30 = table(kknn_K30_pred, test[,"Spam"])
misCl_K30 = 1-sum(diag(confMa_K30)/sum(confMa_K30))

print("Misclassification 4:")
print(misCl_K30)
```

##### Compare the results with step 2.
The misclassification rate is even worse than in step 2. Probably because of the realtively small dataset, which fits a parametric method better. If one would have more data then the K-nearest neighbour could be better for this application, as that works better for non-parametric methods.

## 5.
*Repeat step 4 for $K=1$ and compare the results with step 4. What effect does the decrease of K lead to and why?*

```{r}
#KKNN with K=1
kknn_K1 = kknn(Spam ~ ., train=train, test=test, k=1)
kknn_K1_pred = predict(kknn_K1)

#Split up the model into spam and not spam
kknn_K1_pred <- ifelse(kknn_K1_pred > 0.5, 1, 0) 

confMa_K1 = table(kknn_K1_pred, test[,"Spam"])
misCl_K1 = 1-sum(diag(confMa_K1)/sum(confMa_K1))

print("missclassification 5:")
print(misCl_K1)
```

##### What effect does the decrease of K lead to and why?
The decrease in K leads to a noisier prediction and is thereby worse. It can also lead to overfitting.

\newpage

# Assignment 2
```{r include=FALSE}
set.seed(12345)

# STEP 1:
machines_data<- read.csv2("machines.csv", dec=",")

# STEP 2:


log_likelihood = function(X, theta) {
  if (typeof(X)=="list"){
    X = unlist(X, use.names = FALSE)
  }
  return(length(X)*log(theta) - theta*sum(X))
}

curve(log_likelihood(machines_data, x),xlim=c(0,4), ylim=c(-80,0) , col="red")
# According to plot maxium is between -40 and -43

# Control by calculating maximum theta and inserting to function
maxtheta1 = dim(machines_data)[1]/sum(machines_data) # From deriving the log-likelihood function
print(maxtheta1)
print(log_likelihood(machines_data[1],maxtheta1))

# STEP 3:
maxtheta2 = length(machines_data[1:6,])/sum(machines_data[1:6,])
print(maxtheta2)
curve(log_likelihood(machines_data[1:6,], x), from=0, to=4, col="blue", add = TRUE)



# STEP 4:

bayesian_function = function(X, theta, lambda) {
  if (typeof(X)=="list"){
    X = unlist(X, use.names = FALSE)
  }
  return(length(X)*log(theta)+log(lambda) - theta*(sum(X)+lambda))
}
curve(bayesian_function(machines_data[1], x, 10), from=0, to=4, col="green", add = TRUE)
maxtheta3 = dim(machines_data)[1]/(sum(machines_data)+10) # From deriving the bayesianfunction
print(maxtheta3)
print(bayesian_function(machines_data[1],maxtheta3,10))


# STEP 5:

newdata = rexp(50, maxtheta1)
olddata <- machines_data$ï..Length
print(olddata)
dev.new()
hist(olddata, col="red", xlim=c(0,5), xlab="x")
dev.new()
hist(newdata, col="blue", xlim=c(0,5), xlab="x")
```
This assignment included creating and evaluating probability models by using the log-likelihood function as well as a bayesian model to learn the expected lifetime of a certain machine. With the only input variable length.

## 1-3. Log-likelihood function 
By using the log-likelihood function to find the maximum likelihood value of $\theta$, two models were created; one by using all the given data (48 observations) and one by only using 6 observations.
```{r echo=FALSE}
curve(log_likelihood(machines_data, x), xlab = "Theta" , ylab = "Log-likelihood" ,xlim=c(0,4), ylim=c(-80,0) , col="red", main = "Red: 48 obs. | Blue: 6 obs.")
curve(log_likelihood(machines_data[1:6,], x), from=0, to=4, col="blue", add = TRUE)
```
From the first model we can see that the maximum likelihood value is 1.13 compared to 1.79 in the second model. By compairing the plots of the two models we can also see that the first model is more steep and not so stable when changing $\theta$ and the second model is more stable so the likelihood-value does not change too much depending on $\theta$.

## 4. Bayesian model

The used function, $l(\theta) = log(p(x|\theta) \cdot p(\theta))$, computes what could be interpreted as the log-likelihood of $p(x\cap \theta)$, as bayes theorem gives $p(x|\theta) = \frac{p(x\cap \theta)}{p(\theta)}$.

By comparing this to the result of step 2 (and step 3), it shows that the resulting plot is quite similar to the plot of step 2 with the difference of giving lower values and being more steep. The maximum likelihood value of $\theta$ is somewhat lower (0.91) using the bayesian model compared to the model of step 2 (1.13).

```{r echo=FALSE}
curve(log_likelihood(machines_data, x), xlab = "Theta" , ylab = "Log-likelihood" ,xlim=c(0,4), ylim=c(-80,0) , col="red", main = "Red: 48 obs. | Blue: 6 obs. | Green: Bayesian model")
curve(log_likelihood(machines_data[1:6,], x), from=0, to=4, col="blue", add = TRUE)
curve(bayesian_function(machines_data[1], x, 10), from=0, to=4, col="green", add = TRUE)
```


## 5. Assessment of $\theta$-value from step 2
By generating 50 new observations by using the $\theta$-value obtained from step 2 two histograms were made; one out of the old data and one of the new/generated data - as seen below.
 
```{r echo=FALSE}
hist(olddata, col="red", xlim=c(0,5), xlab="lifetime length")
hist(newdata, col="blue", xlim=c(0,5), xlab="lifetime length")
```
 
When comparing these we can see that the obtained $\theta$-value of step 2 is a good estimation of the machines’ expected lifetime.
 
\newpage